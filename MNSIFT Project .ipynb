{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "52dffc05",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torchvision # for the datasets\n",
    "import torchvision.transforms as transforms\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e27208b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# MNIST DATASET "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e68ece72",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cpu')"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# device config\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "2fe7c547",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hyper Parameters\n",
    "\n",
    "input_size = 784 # 28*28\n",
    "hidden_size = 100 # trail and error\n",
    "num_classes = 10 \n",
    "EPOCHS = 2\n",
    "batch_size = 100\n",
    "learning_rate = 0.001"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "d2952b1e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([100, 1, 28, 28]) torch.Size([100])\n"
     ]
    }
   ],
   "source": [
    "# MNIST Dataloading\n",
    "\n",
    "train_dataset = torchvision.datasets.MNIST(root='./data',train=True,transform=transforms.ToTensor(),download=True)\n",
    "test_dataset = torchvision.datasets.MNIST(root='./data',train=False,transform=transforms.ToTensor() ) \n",
    "\n",
    "train_loader = torch.utils.data.DataLoader(dataset=train_dataset,batch_size=batch_size,shuffle=True)\n",
    "test_loader = torch.utils.data.DataLoader(dataset=test_dataset,batch_size=batch_size,shuffle=False)\n",
    "\n",
    "examples = iter(train_loader)\n",
    "samples, labels = next(examples)\n",
    "print(samples.shape,labels.shape) # 100 batch_size , 1 channel ( no color channel) , 28,28 pixels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "7cf91d01",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 6 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "for i in range(6):\n",
    "    plt.subplot(2,3,i+1)\n",
    "    plt.imshow(samples[i][0] , cmap='gray')\n",
    "    plt.axis('off')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "625d5d3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "class NeuralNet(nn.Module):\n",
    "    def __init__(self,input_size,hidden_size,num_classes):\n",
    "        super(NeuralNet,self).__init__()\n",
    "        self.linear1 = nn.Linear(input_size,hidden_size)\n",
    "        self.relu = nn.ReLU()\n",
    "        self.linear2 = nn.Linear(hidden_size,num_classes)\n",
    "        \n",
    "    def forward(self,x):\n",
    "        out = self.linear1(x)\n",
    "        out = self.relu(out)\n",
    "        out = self.linear2(out)\n",
    "        return out\n",
    "\n",
    "model = NeuralNet(input_size,hidden_size,num_classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "cf41fe74",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loss and Optimizer\n",
    "\n",
    "criterion = nn.CrossEntropyLoss() # thats why we don't use softmax in NeuralNet Class\n",
    "optimizer = torch.optim.Adam(model.parameters(),lr=learning_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "cbdad4d9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 1 / 2, step100/600 , loss = 0.3563\n",
      "epoch 1 / 2, step200/600 , loss = 0.2956\n",
      "epoch 1 / 2, step300/600 , loss = 0.3422\n",
      "epoch 1 / 2, step400/600 , loss = 0.2226\n",
      "epoch 1 / 2, step500/600 , loss = 0.1848\n",
      "epoch 1 / 2, step600/600 , loss = 0.1641\n",
      "epoch 2 / 2, step100/600 , loss = 0.1634\n",
      "epoch 2 / 2, step200/600 , loss = 0.1357\n",
      "epoch 2 / 2, step300/600 , loss = 0.1736\n",
      "epoch 2 / 2, step400/600 , loss = 0.1385\n",
      "epoch 2 / 2, step500/600 , loss = 0.3031\n",
      "epoch 2 / 2, step600/600 , loss = 0.1402\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "'bool' object is not iterable",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[22], line 28\u001b[0m\n\u001b[0;32m     25\u001b[0m n_correct \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m  \u001b[38;5;66;03m# correct predictions\u001b[39;00m\n\u001b[0;32m     26\u001b[0m n_samples \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m\n\u001b[1;32m---> 28\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m images \u001b[38;5;129;01min\u001b[39;00m labels \u001b[38;5;129;01min\u001b[39;00m test_loader:\n\u001b[0;32m     29\u001b[0m     images \u001b[38;5;241m=\u001b[39m images\u001b[38;5;241m.\u001b[39mreshape(\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m,\u001b[38;5;241m28\u001b[39m\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m28\u001b[39m)\u001b[38;5;241m.\u001b[39mto(device)\n\u001b[0;32m     30\u001b[0m     labels \u001b[38;5;241m=\u001b[39m labels\u001b[38;5;241m.\u001b[39mto(device)\n",
      "\u001b[1;31mTypeError\u001b[0m: 'bool' object is not iterable"
     ]
    }
   ],
   "source": [
    "# Training Loop\n",
    "n_total_steps = len(train_loader)\n",
    "\n",
    "for epoch in range(EPOCHS):\n",
    "    for i ,(images,labels) in enumerate(train_loader):\n",
    "        # 100 , 1 ,28,28 ( Shape of image)\n",
    "        # 100,784 (batches,input size)\n",
    "        images = images.reshape(-1,28*28).to(device) # -1 auto configures\n",
    "        labels = labels.to(device)\n",
    "        \n",
    "        # Forward Pass\n",
    "        outputs = model(images)\n",
    "        loss = criterion(outputs,labels)\n",
    "        \n",
    "        # Backward pass\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        if (i+1) % 100 == 0:\n",
    "            print(f\"epoch {epoch+1} / {EPOCHS}, step{i+1}/{n_total_steps} , loss = {loss.item():.4f}\")\n",
    "            \n",
    "# Test and Evualating\n",
    "with torch.no_grad():\n",
    "    n_correct = 0  # correct predictions\n",
    "    n_samples = 0\n",
    "    \n",
    "    for images in labels in test_loader:\n",
    "        images = images.reshape(-1,28*28).to(device)\n",
    "        labels = labels.to(device)\n",
    "        outputs = model(images)\n",
    "        \n",
    "        # torch.max returns value ,index ( prediction )\n",
    "        _, predictions = torch.max(outputs,1)\n",
    "        n_samples += labels.shape[0] # number of samples in the current batch ( should be 100)\n",
    "        n_correct += (predictions == labels).sum().item()\n",
    "        \n",
    "    acc = 100.0 * n_correct / n_samples # Accuracy score in percent\n",
    "    print ( f\"accuracy = {acc}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56be19f1",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
